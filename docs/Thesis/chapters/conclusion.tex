% We did it. This paper rocks and you are lucky to have read it (i.e. brief recap of the entire paper). Also, weâ€™ll do all these other amazing things in the future. 

In this seminar thesis, we provided a comprehensive review and empirical evaluation of the \ac{SSVAE} framework proposed by \cite{narayanaswamy_learning_2017}. By unifying probabilistic graphical models with deep generative networks, this framework offers a principled method for injecting domain knowledge through partial supervision into the representation learning process. This approach addresses the fundamental limitations of purely unsupervised disentanglement, which \cite{locatello_challenging_2018} later proved to be theoretically impossible without such inductive biases.

Through our systematic literature review, we identified critiques such as the semantic conflation problem \citep{joy_learning_2021}, which highlights that rigid partitioning of latent spaces can inadvertently starve continuous variables of semantic content. Furthermore, the field has largely evolved from the semi-supervised paradigm toward weak supervision \citep{locatello_weakly_2020} and causal disentanglement \citep{zhang_causal_2020} to overcome the reliance on expensive explicit labels.

Our own empirical experiments extended the original analysis of \cite{narayanaswamy_learning_2017} by investigating the model's sensitivity to supervision quality and intensity. We demonstrated that the \ac{SSVAE} is remarkably robust to label corruption, maintaining high classification accuracy even when 20\% of the supervision signal is randomised. 

Ultimately, while newer methods have refined the mechanisms for disentanglement, the \ac{SSVAE} remains a foundational framework. It successfully demonstrates that combining structured probabilistic modelling with the flexibility of deep neural networks is a viable path for learning interpretable, data-efficient representations.