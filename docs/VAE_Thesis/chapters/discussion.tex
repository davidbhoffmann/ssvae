In this work, we review the \acp{SSVAE} by \cite{narayanaswamy_learning_2017}, a unified framework for learning disentangled representations by integrating deep generative models with partially-specified probabilistic graphical models. Unlike standard variational autoencoders that often assume a flat latent space, their approach allows for the injection of domain knowledge through structured dependencies while retaining the flexibility of neural networks for function approximation. By allowing for dependency structures they extend previous work on semi-supervised variational auto-encoders from \cite{kingma_semi-supervised_2014}.

% What does the literature think of ssvaes
While most literature builds on the original \ac{SSVAE} paper from \cite{kingma_semi-supervised_2014} (with XX citation son google scholar add reference), there is a also a considerably body of derivative work for \cite{narayanaswamy_learning_2017} (with XX citations on google scholar). However, we only found few works that deeply discuss and critique the method specifically. While \cite{locatello_challenging_2018} validate the use of an inductive bias for disentanglement they also critique the use of labels. This is generally the most frequent critique in the literature \citep{lin_infogan_2020, bouchacourt_multilevel_2017, ke_apgvae_2023, Kim2018DisentanglingBF}. Other papers critique the effect of supervision on disentanglement and mroe general aspects which are not specific to \acp{SSVAE}. We do however find that none of the critiques are substantiate with empirical evidence specific to \acp{SSVAE}.

% What do my experiments think of ssvaes
In our experiments, we investigate the critique of labels being potentially noisy, harming the disentanglement process. While we find that noisy labels decrease classification accuracy of the semi-supervised $y$ latent, we also find that a small share of corrupt labels (up to 20\%)only marginally affects performance.  
We further investigate the effect varying the supervision weight $\alpha$ on the \ac{SSVAE} and find that it improves classification of the $y$ latent whithout leading to overfitting even for values up to 100 and do not affect the final test \ac{ELBO}. 
For both experiments we find that altering the strenght of supervision, through $\alpha$ or weakening the supervision signal through label corruption, has an effect on the accuracy and the disentanglement of $z$.
ohh semanitc conflation problem and my experiments

% Are they a relevant method

% \textbf{Accuracy and ELBO Results}: 
% \begin{itemize} 
%         \item Test accuracy stable up to $\approx$20\% corruption for MNIST digit label.
%         \item As corruption increases, accuracy drops below random chance (10\%).
%         \item ELBO drops slightly with increasing corruption, but overall remains stable.
%     \end{itemize}

% \textbf{Effect on Disentanglement Scores}: 
% \begin{itemize} 
%         \item Disentanglement is higher for smaller supervised set sizes.
%         \item Further, scores increase with label corruption. More pronounced for larger supervised set sizes.
%         \item Indicates that supervision harms disentanglement of the style latent $z$.
% \end{itemize}





While the framework generalizes to arbitrary dependency structures, its practical application in real-world settings with multiple partially observed variables reveals significant limitations. The current formulation relies on a binary distinction between unsupervised data $\mathcal{D}$ and supervised data $\mathcal{D}^{sup}$, assuming a consistent set of available labels for the supervised portion[cite: 116]. However, in complex real-world datasets involving $K$ distinct supervised variables $\mathbf{y} = \{y_1, \dots, y_K\}$, supervision is often heterogeneous; a datapoint may possess annotations for a random subset of variables while others are missing. Under the proposed framework, variables are treated as observed when available and sampled otherwise. Implementing this dynamically in a batched setting becomes non-trivial, as the objective function effectively fractures into $2^K$ potential observation patterns. This combinatorial explosion necessitates a bespoke and brittle implementation of the stochastic computation graph, undermining the flexibility intended by the general framework.

\subsection{Future Directions}
The current implementation relies on static graph definitions, but the natural evolution of this work lies in the integration with probabilistic programming languages. Probabilistic programs would allow for more expressive models involving recursion and control flow, which are currently limited by the static nature of the underlying computation graph. Future work will explore amortizing inference over these dynamic structures, enabling the learning of disentangled representations for increasingly complex, structured data domains such as video or language.